{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQxvO6dhMvtk"
   },
   "source": [
    "# CSE 256: Statistical NLP UCSD Assignment 2\n",
    "## Exploring Word Vectors (12.5 points + 1 bonus point)\n",
    "### <font color='blue'> Due 11:59pm, Monday April 18, 2022 </font>\n",
    "\n",
    "\n",
    "Before you start, make sure you read the README.txt in the same directory as this notebook.\n",
    "\n",
    "\n",
    "**Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCkBxLqTMvtn",
    "outputId": "5b2e53cb-6961-4677-f540-5ec98f2dbfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All Import Statements Defined Here\n",
    "# Note: Do not add to this list.\n",
    "# ----------------\n",
    "\n",
    "import sys\n",
    "assert sys.version_info[0]==3\n",
    "assert sys.version_info[1] >= 5\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4q8E45iMvto"
   },
   "source": [
    "## Word Vectors\n",
    "\n",
    "Word Vectors are often used as a fundamental component for downstream NLP tasks, e.g. question answering, text generation, translation, etc., so it is important to build some intuitions as to their strengths and weaknesses. Here, you will explore word vectors derived from *Word2Vec*. \n",
    "\n",
    "**Note on Terminology:** The terms \"word vectors\" and \"word embeddings\" are often used interchangeably. The term \"embedding\" refers to the fact that we are encoding aspects of a word's meaning in a lower dimensional space. As [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding) states, \"*conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO3hIO8IMvtw"
   },
   "source": [
    "## Word Vectors \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "We shall explore the embeddings produced by word2vec. Please revisit the class notes and lecture slides for more details on the word2vec algorithm. Paper 1 review due May 4th, involves reading the  [word2vec  paper](https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf),  reading it now might help you with this assignment.\n",
    "\n",
    "Run the following cells to load the word2vec vectors into memory. **Note**: If this is your first time to run these cells, i.e. download the embedding model, it will take a couple minutes to run. If you've run these cells before, rerunning them will load the model without redownloading it, which will take about 1 to 2 minutes. In *Colab*, the embeddings are downloaded to the server everytime you restart the notebook). For this reason, you may prefer to work on your local machine where the download only happens once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFrL7EjHMvtw"
   },
   "outputs": [],
   "source": [
    "def load_embedding_model():\n",
    "    \"\"\" Load Word2Vec Vectors\n",
    "        Return:\n",
    "            wv_from_bin: All the embeddings\n",
    "    \"\"\"\n",
    "    import gensim.downloader as api\n",
    "    wv_from_bin = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "    print(\"Loaded vocab size %i\" % len(wv_from_bin.vocab.keys()))\n",
    "    return wv_from_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSWjn1UvMvtw",
    "outputId": "684f6cec-4b59-4e13-f381-cf234c918a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "Loaded vocab size 3000000\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Run Cell to Load Word Vectors\n",
    "# Note: This will take a couple minutes\n",
    "# -----------------------------------\n",
    "wv_from_bin = load_embedding_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnhwd5uuMvtw"
   },
   "source": [
    "#### Note: If you are receiving a \"reset by peer\" error, rerun the cell to restart the download. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1sLJ47CMvtw"
   },
   "source": [
    "\n",
    "### Plot function\n",
    "Let's define a plot function that reduces the vectors from 300-dimensions to 2-dimensions, and visualises them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gI86TKrUMvtw"
   },
   "outputs": [],
   "source": [
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.key_to_index.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQpvbQDFMvtx"
   },
   "source": [
    "### Question 1: Word2vec Plot Analysis [written] (2 points)\n",
    "\n",
    "Run the cell below to plot the 2D GloVe embeddings for `['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']`.\n",
    "\n",
    "What clusters together in 2-dimensional embedding space? What doesn't cluster together that you think should have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "hV6LXSCEMvtx",
    "outputId": "f36f581f-c670-4897-8f63-d55c3a85667c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'iraq']\n",
    "display_pca_scatterplot(wv_from_bin, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w7xtcUSMvtx"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "In my opinion, there are three clusters. \n",
    "<br>However, I think ecuador, kuwait and iraq should be a cluster as they are all countries. bpd, oil and pertroleum should be a cluster as well since bqd is Barrel per day used to describe the oil output.</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ny56x_fMvtx"
   },
   "source": [
    "### Cosine Similarity\n",
    "Now that we have word vectors, we need a way to quantify the similarity between individual words, according to these vectors. One such metric is cosine-similarity. We will be using this to find words that are \"close\" and \"far\" from one another.\n",
    "\n",
    "The [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
    "\n",
    "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEWzAas1Mvtx"
   },
   "source": [
    "### Question 2: Words with Multiple Meanings (2 points) [code + written] \n",
    "Polysemes and homonyms are words that have more than one meaning (see this [wiki page](https://en.wikipedia.org/wiki/Polysemy) to learn more about the difference between polysemes and homonyms ). Find a word with *at least two different meanings* such that the top-10 most similar words (according to cosine similarity) contain related words from *both* meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"rock\" has both \"music\" and \"stone\". You will probably need to try several polysemous or homonymic words before you find one. \n",
    "\n",
    "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?\n",
    "\n",
    "**Note**: You should use the `wv_from_bin.most_similar(word)` function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kTQ066WMvtx",
    "outputId": "41d9c6c7-e9c2-4cec-f955-522e0200daf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glove_compartment', 0.5936945676803589),\n",
       " ('trunks', 0.5714457631111145),\n",
       " ('floorboard', 0.5641743540763855),\n",
       " ('spare_tire', 0.5533804893493652),\n",
       " ('Deja_Adair_bodies', 0.5393577814102173),\n",
       " (\"driver's_side_door\", 0.5388186573982239),\n",
       " ('maroon_Toyota_Camry', 0.5327662825584412),\n",
       " ('nightstand_drawer', 0.5309293270111084),\n",
       " ('undercarriage', 0.5295648574829102),\n",
       " ('passenger_footwell', 0.5287629961967468)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    wv_from_bin.most_similar(positive=['trunk'], topn=10)\n",
    "\n",
    "    # ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D9rhZJc1psV"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVll_55fMvtx"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "I found trunk as the answer. The first meaning of it is a large strong box with a lid used for storing or transporting clothes, books, etc. Therefore, nightstand_drawer is shown on the list. And the second meaning of trunk is the space at the back of a car that you put bags, cases, etc. Therefore, driver's_side_door is shown on the list\n",
    "<br> \n",
    "The reason why many of the polysemous did not work is that one meaning of the word has the majority, such as country. I think it has another meaning as a genre in music, but many countries' names are shown without relaing to music.\n",
    "<br>\n",
    "Another reason is that the Captialization distinguishes the words including Turkey and turkey, one stands for a country and another one stands for an animal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2KRcfnVMvty"
   },
   "source": [
    "### Question 3: Analogies with Word Vectors [written] (2 points)\n",
    "Word vectors have been shown to *sometimes* exhibit the ability to solve analogies. \n",
    "\n",
    "As an example, for the analogy \"man : king :: woman : x\" (read: man is to king as woman is to x), what is x?\n",
    "\n",
    "In the cell below, we show you how to use word vectors to find x using the `most_similar` function from the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar)__. The function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list (while omitting the input words, which are often the most similar; see [this paper](https://www.aclweb.org/anthology/N18-2039.pdf)). The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YysbnlIWMvty",
    "outputId": "47cf4052-0e56-4a3b-bf46-40091973b4c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071),\n",
      " ('monarch', 0.6189674139022827),\n",
      " ('princess', 0.5902431011199951),\n",
      " ('crown_prince', 0.5499460697174072),\n",
      " ('prince', 0.5377321243286133),\n",
      " ('kings', 0.5236844420433044),\n",
      " ('Queen_Consort', 0.5235945582389832),\n",
      " ('queens', 0.518113374710083),\n",
      " ('sultan', 0.5098593235015869),\n",
      " ('monarchy', 0.5087411999702454)]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to answer the analogy -- man : king :: woman : x\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'king'], negative=['man']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOezwAj0Mvty"
   },
   "source": [
    "Let $m$, $k$, $w$, and $x$ denote the word vectors for `man`, `king`, `woman`, and the answer, respectively. Using **only** vectors $m$, $k$, $w$, and the vector arithmetic operators $+$ and $-$ in your answer, what is the expression in which we are maximizing cosine similarity with $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeJ07PABMvty"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "x = k - m + w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaHnrgCeMvty"
   },
   "source": [
    "### Question 4: Finding Analogies [code + written]  (1 point)\n",
    "Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy you came up might not be obvious to the TAs, explain why the analogy holds in one or two sentences.\n",
    "\n",
    "**Note**: You may have to try many analogies to find one that works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpcYBn5yMvty",
    "outputId": "20764cf9-8cd2-4d6b-85b6-8694cf72a7c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tokyo', 0.8115593194961548),\n",
      " ('Osaka', 0.6796455383300781),\n",
      " ('Seoul', 0.6568831205368042),\n",
      " ('Japanese', 0.6475988030433655),\n",
      " ('Nagoya', 0.6425851583480835),\n",
      " ('Maebashi', 0.6409165859222412),\n",
      " ('Yokohama', 0.626289427280426),\n",
      " ('Fukuoka', 0.6085069179534912),\n",
      " ('Osaka_Japan', 0.606758713722229),\n",
      " ('Sapporo', 0.6054472923278809)]\n"
     ]
    }
   ],
   "source": [
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    pprint.pprint(wv_from_bin.most_similar(positive=['Japan', 'Beijing'], negative=['China']))\n",
    "\n",
    "    # ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhwe3RO-Mvty"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "China : Beijing :: Japan : Tokyo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se6pOUqQMvtz"
   },
   "source": [
    "### Question 5: Incorrect Analogy [code + written] (2 point)\n",
    "Find an example of analogy that does *not* hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the (incorrect) value of b according to the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nuZg40J8Mvtz",
    "outputId": "9300e22e-75ae-44f6-ee84-66d7d49a3af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('swimming', 0.682741641998291),\n",
      " ('swims', 0.6299254298210144),\n",
      " ('swimmers', 0.6152995228767395),\n",
      " ('swum', 0.5975209474563599),\n",
      " ('swam', 0.5901205539703369),\n",
      " ('Swimming', 0.5661748647689819),\n",
      " ('swimmer', 0.5531409978866577),\n",
      " ('Swim', 0.5291240811347961),\n",
      " ('doggy_paddle', 0.514002799987793),\n",
      " ('paddling', 0.49313318729400635)]\n"
     ]
    }
   ],
   "source": [
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    pprint.pprint(wv_from_bin.most_similar(positive=['winter', 'swim'], negative=['summer']))\n",
    "\n",
    "    # ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvmrmj2oMvtz"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "Intended summer : swim :: winter : ski\n",
    "\n",
    "Incorrect summer : swim :: winter : swimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDyys-8DMvtz"
   },
   "source": [
    "### Question 6: Guided Analysis of Bias in Word Vectors [written] (2 point)\n",
    "\n",
    "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
    "\n",
    "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"worker\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"worker\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTyRfo1DMvtz",
    "outputId": "64d9a26d-c414-4cbd-df55-0b1bc53c8a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('workers', 0.6582455635070801),\n",
      " ('employee', 0.5805293321609497),\n",
      " ('nurse', 0.5249921679496765),\n",
      " ('receptionist', 0.5142490267753601),\n",
      " ('migrant_worker', 0.5001609325408936),\n",
      " ('Worker', 0.4979269802570343),\n",
      " ('housewife', 0.48609834909439087),\n",
      " ('registered_nurse', 0.4846190810203552),\n",
      " ('laborer', 0.48437267541885376),\n",
      " ('coworker', 0.48212406039237976)]\n",
      "\n",
      "[('workers', 0.5590360164642334),\n",
      " ('laborer', 0.54481041431427),\n",
      " ('foreman', 0.5192232131958008),\n",
      " ('Worker', 0.5161596536636353),\n",
      " ('employee', 0.5094279050827026),\n",
      " ('electrician', 0.49481213092803955),\n",
      " ('janitor', 0.48718899488449097),\n",
      " ('bricklayer', 0.4825313091278076),\n",
      " ('carpenter', 0.47498998045921326),\n",
      " ('workman', 0.4642517566680908)]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be\n",
    "# most dissimilar from.\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'worker'], negative=['man']))\n",
    "print()\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'worker'], negative=['woman']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1t37qzjMvtz"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "As showing in the output, we got nurse, receptionist, migrant_worker, housewife, registered_nurse, coworker for women. These jobs like nurse, receptionist and housewife are jobs for women as they can do better than men.\n",
    "<br>\n",
    "As for men, we got foreman, electrician, janitor, bricklayer, carpenter, workman, involving physical activity, which should be done by men. The difference in jobs indicating the bias of gender in jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI5PRZVYMvtz"
   },
   "source": [
    "### Question 7: Independent Analysis of Bias in Word Vectors [code + written]  ( 1.5 point)\n",
    "\n",
    "Use the `most_similar` function to find another case where some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fW5_tJNeMvtz",
    "outputId": "43264106-55f9-4fe6-861c-eee5fbcd7f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('foodstuffs', 0.44971492886543274),\n",
      " ('foodstuff', 0.4449312388896942),\n",
      " ('nutritious_wholesome', 0.4431554675102234),\n",
      " ('sustenance', 0.4387950301170349),\n",
      " ('meals', 0.4371641278266907),\n",
      " ('basic_necessities', 0.4278228282928467),\n",
      " ('staple_foods', 0.4267752170562744),\n",
      " ('foods', 0.42170023918151855),\n",
      " ('Food', 0.4215978980064392),\n",
      " ('necessities', 0.410751074552536)]\n",
      "\n",
      "[('foods', 0.5348324775695801),\n",
      " ('pet', 0.5268514752388),\n",
      " ('meat', 0.5024101734161377),\n",
      " ('animals', 0.49990469217300415),\n",
      " ('Food', 0.4994952082633972),\n",
      " ('livestock', 0.4868749976158142),\n",
      " ('catfood', 0.4734811782836914),\n",
      " ('dog', 0.4721004068851471),\n",
      " ('animal_welfare', 0.47053539752960205),\n",
      " ('seafood', 0.46918267011642456)]\n"
     ]
    }
   ],
   "source": [
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    pprint.pprint(wv_from_bin.most_similar(positive=['human', 'food'], negative=['animal']))\n",
    "    print()\n",
    "    pprint.pprint(wv_from_bin.most_similar(positive=['animal', 'food'], negative=['human']))\n",
    "\n",
    "    # ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArSm9i1rMvt0"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "I choose human and animal as two category to check their bias about food.\n",
    "<br>\n",
    "As showing above, the difference in human is the words including meals, basic_necessities and staple_foods which are words describing human food.\n",
    "<br>\n",
    "However, in animal food, we can see livestock, catfood and animal_welfare, describing food for different animals. These differences show the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL9C0xPyMvt0"
   },
   "source": [
    "### Question 8: Thinking About Bias [written] (Bonus: 1 point)\n",
    "\n",
    "Give one explanation of how bias gets into the word vectors. What is an experiment that you could do to test for or to measure this source of bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSbxt9EYMvt0"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font>\n",
    "1. Explanation that bias exists in word vectors: These biases are also reflected in the training corpus. For example, women will appear more frequently with other words, so they are learned through skip-gram, cbow, glove, etc. The distance between word vectors will reflect this co-occurrence pattern. \n",
    "2. How to test: directly to count the co-occurence between words in the corpus, such as whether the frequency of woman and related workers appearing together is higher than that of man and related workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nx4fdrswMvt0"
   },
   "source": [
    "# <font color=\"blue\"> Submission Instructions</font>\n",
    "\n",
    "1. Click the Save button at the top of the Jupyter Notebook.\n",
    "2. Select Cell -> All Output -> Clear. This will clear all the outputs from all cells (but will keep the content of all cells). \n",
    "2. Select Cell -> Run All. This will run all the cells in order, and will take several minutes.\n",
    "3. Once you've rerun everything, select File -> Download as -> PDF via LaTeX (If you have trouble using \"PDF via LaTex\", you can also save the webpage as pdf. <font color='blue'> Make sure all your solutions especially the coding parts are displayed in the pdf</font>, it's okay if the provided codes get cut off because lines are not wrapped in code cells).\n",
    "4. Look at the PDF file and make sure all your solutions are there, displayed correctly. The PDF is the only thing your graders will see!\n",
    "5. Submit your PDF on Gradescope.\n",
    "\n",
    "\n",
    "#### <font color=\"blue\"> Acknowledgements</font>\n",
    "This assignment is based on an assignment developed by Chris Manning"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "cnhwd5uuMvtw",
    "0w7xtcUSMvtx",
    "9Ny56x_fMvtx",
    "xeJ07PABMvty",
    "Fhwe3RO-Mvty",
    "jvmrmj2oMvtz",
    "N1t37qzjMvtz",
    "ArSm9i1rMvt0",
    "CSbxt9EYMvt0"
   ],
   "name": "CSE256_Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
